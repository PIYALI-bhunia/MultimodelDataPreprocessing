{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TfIdf_tobacco.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/PIYALI-bhunia/MultimodelDataPreprocessing/blob/main/TfIdf_tobacco.ipynb",
      "authorship_tag": "ABX9TyM/tmGo7K+KiWgLAPpPWd9d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PIYALI-bhunia/MultimodelDataPreprocessing/blob/main/TfIdf_tobacco_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "cOB602Xf9QDO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_root = pathlib.Path('/content/drive/MyDrive/tobaco_OCR/')\n",
        "\n",
        "for item in data_root.iterdir():\n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vg-NvqH-fZn",
        "outputId": "8ae17a30-d833-4781-cd56-0456afcbab52"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/tobaco_OCR/Scientific\n",
            "/content/drive/MyDrive/tobaco_OCR/Resume\n",
            "/content/drive/MyDrive/tobaco_OCR/Report\n",
            "/content/drive/MyDrive/tobaco_OCR/Note\n",
            "/content/drive/MyDrive/tobaco_OCR/Memo\n",
            "/content/drive/MyDrive/tobaco_OCR/News\n",
            "/content/drive/MyDrive/tobaco_OCR/Letter\n",
            "/content/drive/MyDrive/tobaco_OCR/Form\n",
            "/content/drive/MyDrive/tobaco_OCR/Email\n",
            "/content/drive/MyDrive/tobaco_OCR/ADVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_file_paths_and_labels(data_root):\n",
        "     text_paths = [str(path) for path in data_root.glob('*/*.txt')]\n",
        "     labels = [p.split(\"/\")[-2] for p in text_paths]\n",
        "     return text_paths, labels\n",
        "\n",
        "text_paths, labels = get_file_paths_and_labels(data_root)\n",
        "print(len(text_paths))\n",
        "print(labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pCEs_vr-fbT",
        "outputId": "8e960f63-8c03-4e74-cc51-fb6eada5d3da"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3482\n",
            "['Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Scientific', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Report', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Note', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'Memo', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'News', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Letter', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Form', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'Email', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE', 'ADVE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "for this_text in text_paths:\n",
        "    with open(this_text) as f:\n",
        "        lines = f.readlines()\n",
        "        lines  = ' '.join(lines)\n",
        "        texts.append(lines)\n",
        "        \n",
        "\n",
        "print(len(texts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgUrYWzD-fgL",
        "outputId": "9946437c-3421-4f74-f285-e4e449a1bba7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(list(zip(text_paths, texts,labels)),\n",
        "               columns =['path', 'text','our_label'])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "8rRiaARQ-fjC",
        "outputId": "1ca2ff26-eea0-4eac-d89d-5090488aae20"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   path  \\\n",
              "0     /content/drive/MyDrive/tobaco_OCR/Scientific/2...   \n",
              "1     /content/drive/MyDrive/tobaco_OCR/Scientific/2...   \n",
              "2     /content/drive/MyDrive/tobaco_OCR/Scientific/P...   \n",
              "3     /content/drive/MyDrive/tobaco_OCR/Scientific/2...   \n",
              "4     /content/drive/MyDrive/tobaco_OCR/Scientific/1...   \n",
              "...                                                 ...   \n",
              "3477  /content/drive/MyDrive/tobaco_OCR/ADVE/2064932...   \n",
              "3478  /content/drive/MyDrive/tobaco_OCR/ADVE/2070715...   \n",
              "3479  /content/drive/MyDrive/tobaco_OCR/ADVE/2061000...   \n",
              "3480  /content/drive/MyDrive/tobaco_OCR/ADVE/2084426...   \n",
              "3481  /content/drive/MyDrive/tobaco_OCR/ADVE/5127256...   \n",
              "\n",
              "                                                   text   our_label  \n",
              "0     PROJECT TITLE: Project Tomorrow CON F{ 0 EN I ...  Scientific  \n",
              "1     PAGE 0\\n De. W. Fink\\n Vice Director Research\\...  Scientific  \n",
              "2     Bf). yas- 737 fet /970\\n Cre part)\\n THE VETER...  Scientific  \n",
              "3     Measurement of the Sampling Efficiency of ‘Cur...  Scientific  \n",
              "4     H\\n a\\n —_ #\\n 786\\n New Scientest 29 Septerob...  Scientific  \n",
              "...                                                 ...         ...  \n",
              "3477  as\\n Kent Golden Lights Menthol #107\\n People ...        ADVE  \n",
              "3478  Dare to be More:\\n a\\n ta\\n © 1986 (11R.J. REY...        ADVE  \n",
              "3479                                      \\n 2061000301        ADVE  \n",
              "3480  \\n \\n \\n \\n eS\\n MARIBORO L #835\\n COUNTRY WEE...        ADVE  \n",
              "3481                                                           ADVE  \n",
              "\n",
              "[3482 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d6c026b-250f-4934-a19b-0eaa9a2d59f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>text</th>\n",
              "      <th>our_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/Scientific/2...</td>\n",
              "      <td>PROJECT TITLE: Project Tomorrow CON F{ 0 EN I ...</td>\n",
              "      <td>Scientific</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/Scientific/2...</td>\n",
              "      <td>PAGE 0\\n De. W. Fink\\n Vice Director Research\\...</td>\n",
              "      <td>Scientific</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/Scientific/P...</td>\n",
              "      <td>Bf). yas- 737 fet /970\\n Cre part)\\n THE VETER...</td>\n",
              "      <td>Scientific</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/Scientific/2...</td>\n",
              "      <td>Measurement of the Sampling Efficiency of ‘Cur...</td>\n",
              "      <td>Scientific</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/Scientific/1...</td>\n",
              "      <td>H\\n a\\n —_ #\\n 786\\n New Scientest 29 Septerob...</td>\n",
              "      <td>Scientific</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3477</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/ADVE/2064932...</td>\n",
              "      <td>as\\n Kent Golden Lights Menthol #107\\n People ...</td>\n",
              "      <td>ADVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3478</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/ADVE/2070715...</td>\n",
              "      <td>Dare to be More:\\n a\\n ta\\n © 1986 (11R.J. REY...</td>\n",
              "      <td>ADVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3479</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/ADVE/2061000...</td>\n",
              "      <td>\\n 2061000301</td>\n",
              "      <td>ADVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3480</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/ADVE/2084426...</td>\n",
              "      <td>\\n \\n \\n \\n eS\\n MARIBORO L #835\\n COUNTRY WEE...</td>\n",
              "      <td>ADVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3481</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/ADVE/5127256...</td>\n",
              "      <td></td>\n",
              "      <td>ADVE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3482 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d6c026b-250f-4934-a19b-0eaa9a2d59f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d6c026b-250f-4934-a19b-0eaa9a2d59f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d6c026b-250f-4934-a19b-0eaa9a2d59f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "df['text'] = [re.sub(r'[^\\w\\s]','',s) for s in df['text']]\n",
        "df['text']  = [s.replace('\\n','') for s in df['text']]\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "P5WOPZgq-flg",
        "outputId": "748c1140-5ade-4281-c265-7f42b80640bf"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   path  \\\n",
              "0     /content/drive/MyDrive/tobaco_OCR/Scientific/2...   \n",
              "1     /content/drive/MyDrive/tobaco_OCR/Scientific/2...   \n",
              "2     /content/drive/MyDrive/tobaco_OCR/Scientific/P...   \n",
              "3     /content/drive/MyDrive/tobaco_OCR/Scientific/2...   \n",
              "4     /content/drive/MyDrive/tobaco_OCR/Scientific/1...   \n",
              "...                                                 ...   \n",
              "3477  /content/drive/MyDrive/tobaco_OCR/ADVE/2064932...   \n",
              "3478  /content/drive/MyDrive/tobaco_OCR/ADVE/2070715...   \n",
              "3479  /content/drive/MyDrive/tobaco_OCR/ADVE/2061000...   \n",
              "3480  /content/drive/MyDrive/tobaco_OCR/ADVE/2084426...   \n",
              "3481  /content/drive/MyDrive/tobaco_OCR/ADVE/5127256...   \n",
              "\n",
              "                                                   text   our_label  \n",
              "0     PROJECT TITLE Project Tomorrow CON F 0 EN I AL...  Scientific  \n",
              "1     PAGE 0 De W Fink Vice Director Research Fabriq...  Scientific  \n",
              "2     Bf yas 737 fet 970 Cre part THE VETERANS ADMIN...  Scientific  \n",
              "3     Measurement of the Sampling Efficiency of Curr...  Scientific  \n",
              "4     H a _  786 New Scientest 29 Septerober 1977   ...  Scientific  \n",
              "...                                                 ...         ...  \n",
              "3477  as Kent Golden Lights Menthol 107 People 1978 ...        ADVE  \n",
              "3478  Dare to be More a ta  1986 11RJ REYNOLDS TOBAC...        ADVE  \n",
              "3479                                         2061000301        ADVE  \n",
              "3480      eS MARIBORO L 835 COUNTRY WEEKLY 2800     ...        ADVE  \n",
              "3481                                                           ADVE  \n",
              "\n",
              "[3482 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1b50d32-3f41-4f62-bc0b-f06d49ea5d0c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>text</th>\n",
              "      <th>our_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/Scientific/2...</td>\n",
              "      <td>PROJECT TITLE Project Tomorrow CON F 0 EN I AL...</td>\n",
              "      <td>Scientific</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/Scientific/2...</td>\n",
              "      <td>PAGE 0 De W Fink Vice Director Research Fabriq...</td>\n",
              "      <td>Scientific</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/Scientific/P...</td>\n",
              "      <td>Bf yas 737 fet 970 Cre part THE VETERANS ADMIN...</td>\n",
              "      <td>Scientific</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/Scientific/2...</td>\n",
              "      <td>Measurement of the Sampling Efficiency of Curr...</td>\n",
              "      <td>Scientific</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/Scientific/1...</td>\n",
              "      <td>H a _  786 New Scientest 29 Septerober 1977   ...</td>\n",
              "      <td>Scientific</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3477</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/ADVE/2064932...</td>\n",
              "      <td>as Kent Golden Lights Menthol 107 People 1978 ...</td>\n",
              "      <td>ADVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3478</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/ADVE/2070715...</td>\n",
              "      <td>Dare to be More a ta  1986 11RJ REYNOLDS TOBAC...</td>\n",
              "      <td>ADVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3479</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/ADVE/2061000...</td>\n",
              "      <td>2061000301</td>\n",
              "      <td>ADVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3480</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/ADVE/2084426...</td>\n",
              "      <td>eS MARIBORO L 835 COUNTRY WEEKLY 2800     ...</td>\n",
              "      <td>ADVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3481</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/ADVE/5127256...</td>\n",
              "      <td></td>\n",
              "      <td>ADVE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3482 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1b50d32-3f41-4f62-bc0b-f06d49ea5d0c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c1b50d32-3f41-4f62-bc0b-f06d49ea5d0c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c1b50d32-3f41-4f62-bc0b-f06d49ea5d0c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spacy word Preprocessing"
      ],
      "metadata": {
        "id": "cWvy88Arqztl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Tokenize, Lemmatize, stopwords removal\n",
        "import spacy \n",
        "import nltk\n",
        "nlp = spacy.load(\"en\", disable=['parser', 'tagger', 'ner'])\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stops = stopwords.words(\"english\")\n",
        "\n",
        "def normalize(comment, lowercase, remove_stopwords):\n",
        "    if lowercase:\n",
        "        comment = comment.lower()\n",
        "    comment = nlp(comment)\n",
        "    lemmatized = list()\n",
        "    for word in comment:\n",
        "        lemma = word.lemma_.strip()\n",
        "        if lemma:\n",
        "            if not remove_stopwords or (remove_stopwords and lemma not in stops):\n",
        "                lemmatized.append(lemma)\n",
        "    return \" \".join(lemmatized)\n",
        "\n",
        "\n",
        "df['text'] = df['text'].apply(normalize, lowercase=True, remove_stopwords=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmzWOtkR-fn5",
        "outputId": "6b7dc5fc-be9c-437b-ef28-6b9ce9606ccf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "_7y9L3bJ-fpy",
        "outputId": "748e020f-8569-41c2-e8f3-246c1a8e0bbd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   path  \\\n",
              "0     /content/drive/MyDrive/tobaco_OCR/Scientific/2...   \n",
              "1     /content/drive/MyDrive/tobaco_OCR/Scientific/2...   \n",
              "2     /content/drive/MyDrive/tobaco_OCR/Scientific/P...   \n",
              "3     /content/drive/MyDrive/tobaco_OCR/Scientific/2...   \n",
              "4     /content/drive/MyDrive/tobaco_OCR/Scientific/1...   \n",
              "...                                                 ...   \n",
              "3477  /content/drive/MyDrive/tobaco_OCR/ADVE/2064932...   \n",
              "3478  /content/drive/MyDrive/tobaco_OCR/ADVE/2070715...   \n",
              "3479  /content/drive/MyDrive/tobaco_OCR/ADVE/2061000...   \n",
              "3480  /content/drive/MyDrive/tobaco_OCR/ADVE/2084426...   \n",
              "3481  /content/drive/MyDrive/tobaco_OCR/ADVE/5127256...   \n",
              "\n",
              "                                                   text   our_label  \n",
              "0     project title project tomorrow con f 0 en al p...  Scientific  \n",
              "1     page 0 de w fink vice director research fabriq...  Scientific  \n",
              "2     bf yas 737 fet 970 cre part veteran administra...  Scientific  \n",
              "3     measurement sample efficiency currently availa...  Scientific  \n",
              "4     h _ 786 new scientest 29 septerober 1977 oe ge...  Scientific  \n",
              "...                                                 ...         ...  \n",
              "3477  kent golden light menthol 107 people 1978 ah y...        ADVE  \n",
              "3478  dare much ta 1986 11rj reynolds tobacco co 665...        ADVE  \n",
              "3479                                         2061000301        ADVE  \n",
              "3480  es mariboro l 835 country weekly 2800 te 8 2a ...        ADVE  \n",
              "3481                                                           ADVE  \n",
              "\n",
              "[3482 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-116cb5cf-665f-481c-981e-79d3cd4e1f22\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>text</th>\n",
              "      <th>our_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/Scientific/2...</td>\n",
              "      <td>project title project tomorrow con f 0 en al p...</td>\n",
              "      <td>Scientific</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/Scientific/2...</td>\n",
              "      <td>page 0 de w fink vice director research fabriq...</td>\n",
              "      <td>Scientific</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/Scientific/P...</td>\n",
              "      <td>bf yas 737 fet 970 cre part veteran administra...</td>\n",
              "      <td>Scientific</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/Scientific/2...</td>\n",
              "      <td>measurement sample efficiency currently availa...</td>\n",
              "      <td>Scientific</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/Scientific/1...</td>\n",
              "      <td>h _ 786 new scientest 29 septerober 1977 oe ge...</td>\n",
              "      <td>Scientific</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3477</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/ADVE/2064932...</td>\n",
              "      <td>kent golden light menthol 107 people 1978 ah y...</td>\n",
              "      <td>ADVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3478</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/ADVE/2070715...</td>\n",
              "      <td>dare much ta 1986 11rj reynolds tobacco co 665...</td>\n",
              "      <td>ADVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3479</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/ADVE/2061000...</td>\n",
              "      <td>2061000301</td>\n",
              "      <td>ADVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3480</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/ADVE/2084426...</td>\n",
              "      <td>es mariboro l 835 country weekly 2800 te 8 2a ...</td>\n",
              "      <td>ADVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3481</th>\n",
              "      <td>/content/drive/MyDrive/tobaco_OCR/ADVE/5127256...</td>\n",
              "      <td></td>\n",
              "      <td>ADVE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3482 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-116cb5cf-665f-481c-981e-79d3cd4e1f22')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-116cb5cf-665f-481c-981e-79d3cd4e1f22 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-116cb5cf-665f-481c-981e-79d3cd4e1f22');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tf_Idf"
      ],
      "metadata": {
        "id": "LfOy4ZBnrJTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform(df['text'])\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "matrix = vectors.todense()\n",
        "\n",
        "tfidf_df = pd.DataFrame(matrix, columns = feature_names)\n",
        "\n",
        "tfidf_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "2e6xvk1m-fsR",
        "outputId": "e05ea000-ca63-4b17-c05a-3ec50897f49c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       00  000  0000  00000  000000  0000000  00000001  0000029  00001  \\\n",
              "0     0.0  0.0   0.0    0.0     0.0      0.0       0.0      0.0    0.0   \n",
              "1     0.0  0.0   0.0    0.0     0.0      0.0       0.0      0.0    0.0   \n",
              "2     0.0  0.0   0.0    0.0     0.0      0.0       0.0      0.0    0.0   \n",
              "3     0.0  0.0   0.0    0.0     0.0      0.0       0.0      0.0    0.0   \n",
              "4     0.0  0.0   0.0    0.0     0.0      0.0       0.0      0.0    0.0   \n",
              "...   ...  ...   ...    ...     ...      ...       ...      ...    ...   \n",
              "3477  0.0  0.0   0.0    0.0     0.0      0.0       0.0      0.0    0.0   \n",
              "3478  0.0  0.0   0.0    0.0     0.0      0.0       0.0      0.0    0.0   \n",
              "3479  0.0  0.0   0.0    0.0     0.0      0.0       0.0      0.0    0.0   \n",
              "3480  0.0  0.0   0.0    0.0     0.0      0.0       0.0      0.0    0.0   \n",
              "3481  0.0  0.0   0.0    0.0     0.0      0.0       0.0      0.0    0.0   \n",
              "\n",
              "      0000110  ...  éti  éva  éverienn  évidents  évlzed28  éwopart   éx  \\\n",
              "0         0.0  ...  0.0  0.0       0.0       0.0       0.0      0.0  0.0   \n",
              "1         0.0  ...  0.0  0.0       0.0       0.0       0.0      0.0  0.0   \n",
              "2         0.0  ...  0.0  0.0       0.0       0.0       0.0      0.0  0.0   \n",
              "3         0.0  ...  0.0  0.0       0.0       0.0       0.0      0.0  0.0   \n",
              "4         0.0  ...  0.0  0.0       0.0       0.0       0.0      0.0  0.0   \n",
              "...       ...  ...  ...  ...       ...       ...       ...      ...  ...   \n",
              "3477      0.0  ...  0.0  0.0       0.0       0.0       0.0      0.0  0.0   \n",
              "3478      0.0  ...  0.0  0.0       0.0       0.0       0.0      0.0  0.0   \n",
              "3479      0.0  ...  0.0  0.0       0.0       0.0       0.0      0.0  0.0   \n",
              "3480      0.0  ...  0.0  0.0       0.0       0.0       0.0      0.0  0.0   \n",
              "3481      0.0  ...  0.0  0.0       0.0       0.0       0.0      0.0  0.0   \n",
              "\n",
              "      éxcépt  éxet   éy  \n",
              "0        0.0   0.0  0.0  \n",
              "1        0.0   0.0  0.0  \n",
              "2        0.0   0.0  0.0  \n",
              "3        0.0   0.0  0.0  \n",
              "4        0.0   0.0  0.0  \n",
              "...      ...   ...  ...  \n",
              "3477     0.0   0.0  0.0  \n",
              "3478     0.0   0.0  0.0  \n",
              "3479     0.0   0.0  0.0  \n",
              "3480     0.0   0.0  0.0  \n",
              "3481     0.0   0.0  0.0  \n",
              "\n",
              "[3482 rows x 77650 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d121133-7f62-48c2-a778-b64ed3f3a86d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>0000</th>\n",
              "      <th>00000</th>\n",
              "      <th>000000</th>\n",
              "      <th>0000000</th>\n",
              "      <th>00000001</th>\n",
              "      <th>0000029</th>\n",
              "      <th>00001</th>\n",
              "      <th>0000110</th>\n",
              "      <th>...</th>\n",
              "      <th>éti</th>\n",
              "      <th>éva</th>\n",
              "      <th>éverienn</th>\n",
              "      <th>évidents</th>\n",
              "      <th>évlzed28</th>\n",
              "      <th>éwopart</th>\n",
              "      <th>éx</th>\n",
              "      <th>éxcépt</th>\n",
              "      <th>éxet</th>\n",
              "      <th>éy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3477</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3478</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3479</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3480</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3481</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3482 rows × 77650 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d121133-7f62-48c2-a778-b64ed3f3a86d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d121133-7f62-48c2-a778-b64ed3f3a86d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d121133-7f62-48c2-a778-b64ed3f3a86d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "tfidf_df['data_label']= le.fit_transform(df['our_label'])\n",
        "\n"
      ],
      "metadata": {
        "id": "MnmZuBta-fu0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "4ycfOvA4YEdS",
        "outputId": "9c4cc37a-8009-4b0b-a81c-c76bd542d364"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       00  000  0000  00000  000000  0000000  00000001  0000029  00001  \\\n",
              "0     0.0  0.0   0.0    0.0     0.0      0.0       0.0      0.0    0.0   \n",
              "1     0.0  0.0   0.0    0.0     0.0      0.0       0.0      0.0    0.0   \n",
              "2     0.0  0.0   0.0    0.0     0.0      0.0       0.0      0.0    0.0   \n",
              "3     0.0  0.0   0.0    0.0     0.0      0.0       0.0      0.0    0.0   \n",
              "4     0.0  0.0   0.0    0.0     0.0      0.0       0.0      0.0    0.0   \n",
              "...   ...  ...   ...    ...     ...      ...       ...      ...    ...   \n",
              "3477  0.0  0.0   0.0    0.0     0.0      0.0       0.0      0.0    0.0   \n",
              "3478  0.0  0.0   0.0    0.0     0.0      0.0       0.0      0.0    0.0   \n",
              "3479  0.0  0.0   0.0    0.0     0.0      0.0       0.0      0.0    0.0   \n",
              "3480  0.0  0.0   0.0    0.0     0.0      0.0       0.0      0.0    0.0   \n",
              "3481  0.0  0.0   0.0    0.0     0.0      0.0       0.0      0.0    0.0   \n",
              "\n",
              "      0000110  ...  éva  éverienn  évidents  évlzed28  éwopart   éx  éxcépt  \\\n",
              "0         0.0  ...  0.0       0.0       0.0       0.0      0.0  0.0     0.0   \n",
              "1         0.0  ...  0.0       0.0       0.0       0.0      0.0  0.0     0.0   \n",
              "2         0.0  ...  0.0       0.0       0.0       0.0      0.0  0.0     0.0   \n",
              "3         0.0  ...  0.0       0.0       0.0       0.0      0.0  0.0     0.0   \n",
              "4         0.0  ...  0.0       0.0       0.0       0.0      0.0  0.0     0.0   \n",
              "...       ...  ...  ...       ...       ...       ...      ...  ...     ...   \n",
              "3477      0.0  ...  0.0       0.0       0.0       0.0      0.0  0.0     0.0   \n",
              "3478      0.0  ...  0.0       0.0       0.0       0.0      0.0  0.0     0.0   \n",
              "3479      0.0  ...  0.0       0.0       0.0       0.0      0.0  0.0     0.0   \n",
              "3480      0.0  ...  0.0       0.0       0.0       0.0      0.0  0.0     0.0   \n",
              "3481      0.0  ...  0.0       0.0       0.0       0.0      0.0  0.0     0.0   \n",
              "\n",
              "      éxet   éy  data_label  \n",
              "0      0.0  0.0           9  \n",
              "1      0.0  0.0           9  \n",
              "2      0.0  0.0           9  \n",
              "3      0.0  0.0           9  \n",
              "4      0.0  0.0           9  \n",
              "...    ...  ...         ...  \n",
              "3477   0.0  0.0           0  \n",
              "3478   0.0  0.0           0  \n",
              "3479   0.0  0.0           0  \n",
              "3480   0.0  0.0           0  \n",
              "3481   0.0  0.0           0  \n",
              "\n",
              "[3482 rows x 77651 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-882b9234-c62b-43d4-9061-9fedc2904f72\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>0000</th>\n",
              "      <th>00000</th>\n",
              "      <th>000000</th>\n",
              "      <th>0000000</th>\n",
              "      <th>00000001</th>\n",
              "      <th>0000029</th>\n",
              "      <th>00001</th>\n",
              "      <th>0000110</th>\n",
              "      <th>...</th>\n",
              "      <th>éva</th>\n",
              "      <th>éverienn</th>\n",
              "      <th>évidents</th>\n",
              "      <th>évlzed28</th>\n",
              "      <th>éwopart</th>\n",
              "      <th>éx</th>\n",
              "      <th>éxcépt</th>\n",
              "      <th>éxet</th>\n",
              "      <th>éy</th>\n",
              "      <th>data_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3477</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3478</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3479</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3480</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3481</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3482 rows × 77651 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-882b9234-c62b-43d4-9061-9fedc2904f72')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-882b9234-c62b-43d4-9061-9fedc2904f72 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-882b9234-c62b-43d4-9061-9fedc2904f72');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X =tfidf_df.iloc[:,:-1]\n",
        "y =tfidf_df['data_label']\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onRFzULTYEgv",
        "outputId": "bfd507fb-5e64-46f9-e5ab-7e3363f467cb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3482, 77650)\n",
            "(3482,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HDfwgS6cH1a7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state =10)"
      ],
      "metadata": {
        "id": "9JVtnWt7k3Jm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(X_train)\n",
        "x_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "qMSf2WAGMLK3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cgT0fDy2MLM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9dIFHU48MLU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP Classifier "
      ],
      "metadata": {
        "id": "RDF1zXz4IVMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "ihlcoJmDWMZG"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Initialising the ANN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(layers.Flatten(input_shape= (77650,)))\n",
        "\n",
        "classifier.add(Dense(units= 512, kernel_initializer='he_uniform',activation='relu'))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(units= 256, kernel_initializer='he_uniform',activation='relu'))\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(units= 10, kernel_initializer='he_uniform', activation = 'softmax'))"
      ],
      "metadata": {
        "id": "Rsm_ObcaH1dw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy' , metrics = ['accuracy'])\n",
        "classifier.summary()"
      ],
      "metadata": {
        "id": "iQEvJocbRFyl",
        "outputId": "afca8c92-424c-404b-eddf-01aac6a514e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 77650)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               39757312  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 39,891,210\n",
            "Trainable params: 39,891,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the ANN to the Training set\n",
        "model_history = classifier.fit(x_train_scaled, y_train, validation_split=0.33, batch_size=32, epochs = 100)"
      ],
      "metadata": {
        "id": "NwRRzeR_Xq4z",
        "outputId": "bc43caed-1c93-49fd-9691-416fd8895753",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "59/59 [==============================] - 17s 274ms/step - loss: 4.3868 - accuracy: 0.5013 - val_loss: 3.5830 - val_accuracy: 0.6435\n",
            "Epoch 2/100\n",
            "59/59 [==============================] - 16s 271ms/step - loss: 1.1926 - accuracy: 0.9582 - val_loss: 8.4996 - val_accuracy: 0.6141\n",
            "Epoch 3/100\n",
            "59/59 [==============================] - 15s 253ms/step - loss: 0.5707 - accuracy: 0.9769 - val_loss: 24.7332 - val_accuracy: 0.5261\n",
            "Epoch 4/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.3441 - accuracy: 0.9887 - val_loss: 29.3017 - val_accuracy: 0.5391\n",
            "Epoch 5/100\n",
            "59/59 [==============================] - 15s 255ms/step - loss: 0.2854 - accuracy: 0.9936 - val_loss: 16.6049 - val_accuracy: 0.5435\n",
            "Epoch 6/100\n",
            "59/59 [==============================] - 15s 253ms/step - loss: 0.1067 - accuracy: 0.9962 - val_loss: 41.7535 - val_accuracy: 0.5022\n",
            "Epoch 7/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.3418 - accuracy: 0.9866 - val_loss: 26.1486 - val_accuracy: 0.5500\n",
            "Epoch 8/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.0282 - accuracy: 0.9930 - val_loss: 24.8290 - val_accuracy: 0.5315\n",
            "Epoch 9/100\n",
            "59/59 [==============================] - 16s 264ms/step - loss: 0.0183 - accuracy: 0.9962 - val_loss: 25.1512 - val_accuracy: 0.4978\n",
            "Epoch 10/100\n",
            "59/59 [==============================] - 15s 255ms/step - loss: 0.0251 - accuracy: 0.9968 - val_loss: 24.7912 - val_accuracy: 0.5304\n",
            "Epoch 11/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.0168 - accuracy: 0.9962 - val_loss: 24.7604 - val_accuracy: 0.5250\n",
            "Epoch 12/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.0345 - accuracy: 0.9952 - val_loss: 24.5612 - val_accuracy: 0.5391\n",
            "Epoch 13/100\n",
            "59/59 [==============================] - 15s 255ms/step - loss: 0.0139 - accuracy: 0.9962 - val_loss: 24.4340 - val_accuracy: 0.5261\n",
            "Epoch 14/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 24.5158 - val_accuracy: 0.5304\n",
            "Epoch 15/100\n",
            "59/59 [==============================] - 15s 253ms/step - loss: 0.0132 - accuracy: 0.9968 - val_loss: 24.3460 - val_accuracy: 0.5446\n",
            "Epoch 16/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 24.3111 - val_accuracy: 0.5446\n",
            "Epoch 17/100\n",
            "59/59 [==============================] - 15s 255ms/step - loss: 0.0068 - accuracy: 0.9968 - val_loss: 24.3085 - val_accuracy: 0.5402\n",
            "Epoch 18/100\n",
            "59/59 [==============================] - 15s 257ms/step - loss: 0.0082 - accuracy: 0.9957 - val_loss: 24.3376 - val_accuracy: 0.5348\n",
            "Epoch 19/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 24.2741 - val_accuracy: 0.5174\n",
            "Epoch 20/100\n",
            "59/59 [==============================] - 15s 252ms/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 24.1844 - val_accuracy: 0.5511\n",
            "Epoch 21/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 23.9176 - val_accuracy: 0.5239\n",
            "Epoch 22/100\n",
            "59/59 [==============================] - 15s 252ms/step - loss: 0.0081 - accuracy: 0.9962 - val_loss: 24.0605 - val_accuracy: 0.5359\n",
            "Epoch 23/100\n",
            "59/59 [==============================] - 15s 252ms/step - loss: 0.0200 - accuracy: 0.9952 - val_loss: 23.2578 - val_accuracy: 0.5315\n",
            "Epoch 24/100\n",
            "59/59 [==============================] - 15s 252ms/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 23.2017 - val_accuracy: 0.5196\n",
            "Epoch 25/100\n",
            "59/59 [==============================] - 15s 256ms/step - loss: 0.0069 - accuracy: 0.9957 - val_loss: 23.2156 - val_accuracy: 0.5272\n",
            "Epoch 26/100\n",
            "59/59 [==============================] - 15s 253ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 23.2250 - val_accuracy: 0.5065\n",
            "Epoch 27/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.0082 - accuracy: 0.9957 - val_loss: 23.1248 - val_accuracy: 0.5130\n",
            "Epoch 28/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.0066 - accuracy: 0.9973 - val_loss: 23.2067 - val_accuracy: 0.5380\n",
            "Epoch 29/100\n",
            "59/59 [==============================] - 15s 253ms/step - loss: 0.0065 - accuracy: 0.9962 - val_loss: 23.1233 - val_accuracy: 0.5228\n",
            "Epoch 30/100\n",
            "59/59 [==============================] - 15s 252ms/step - loss: 0.0097 - accuracy: 0.9962 - val_loss: 23.1082 - val_accuracy: 0.5217\n",
            "Epoch 31/100\n",
            "59/59 [==============================] - 15s 252ms/step - loss: 0.0062 - accuracy: 0.9973 - val_loss: 23.1740 - val_accuracy: 0.5250\n",
            "Epoch 32/100\n",
            "59/59 [==============================] - 15s 251ms/step - loss: 0.0083 - accuracy: 0.9952 - val_loss: 23.1169 - val_accuracy: 0.5228\n",
            "Epoch 33/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.0101 - accuracy: 0.9962 - val_loss: 22.7126 - val_accuracy: 0.5391\n",
            "Epoch 34/100\n",
            "59/59 [==============================] - 15s 258ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 22.8094 - val_accuracy: 0.5283\n",
            "Epoch 35/100\n",
            "59/59 [==============================] - 15s 252ms/step - loss: 0.0083 - accuracy: 0.9952 - val_loss: 22.8446 - val_accuracy: 0.5239\n",
            "Epoch 36/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.0058 - accuracy: 0.9962 - val_loss: 22.8648 - val_accuracy: 0.5109\n",
            "Epoch 37/100\n",
            "59/59 [==============================] - 15s 252ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 22.8094 - val_accuracy: 0.4772\n",
            "Epoch 38/100\n",
            "59/59 [==============================] - 15s 252ms/step - loss: 0.0108 - accuracy: 0.9952 - val_loss: 22.2664 - val_accuracy: 0.5446\n",
            "Epoch 39/100\n",
            "59/59 [==============================] - 15s 258ms/step - loss: 0.0116 - accuracy: 0.9946 - val_loss: 21.4682 - val_accuracy: 0.4533\n",
            "Epoch 40/100\n",
            "59/59 [==============================] - 15s 252ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 21.5044 - val_accuracy: 0.4902\n",
            "Epoch 41/100\n",
            "59/59 [==============================] - 15s 252ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 21.4959 - val_accuracy: 0.5272\n",
            "Epoch 42/100\n",
            "59/59 [==============================] - 15s 257ms/step - loss: 0.0100 - accuracy: 0.9952 - val_loss: 21.0902 - val_accuracy: 0.5065\n",
            "Epoch 43/100\n",
            "59/59 [==============================] - 15s 251ms/step - loss: 0.0052 - accuracy: 0.9979 - val_loss: 20.9282 - val_accuracy: 0.4859\n",
            "Epoch 44/100\n",
            "59/59 [==============================] - 15s 257ms/step - loss: 0.0064 - accuracy: 0.9968 - val_loss: 20.9512 - val_accuracy: 0.4913\n",
            "Epoch 45/100\n",
            "59/59 [==============================] - 15s 258ms/step - loss: 0.0062 - accuracy: 0.9973 - val_loss: 20.8752 - val_accuracy: 0.5239\n",
            "Epoch 46/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.0058 - accuracy: 0.9962 - val_loss: 20.9994 - val_accuracy: 0.5098\n",
            "Epoch 47/100\n",
            "59/59 [==============================] - 15s 256ms/step - loss: 0.0057 - accuracy: 0.9973 - val_loss: 21.0587 - val_accuracy: 0.5065\n",
            "Epoch 48/100\n",
            "59/59 [==============================] - 15s 258ms/step - loss: 0.0054 - accuracy: 0.9973 - val_loss: 21.1381 - val_accuracy: 0.4935\n",
            "Epoch 49/100\n",
            "59/59 [==============================] - 15s 258ms/step - loss: 0.0057 - accuracy: 0.9973 - val_loss: 21.1188 - val_accuracy: 0.4989\n",
            "Epoch 50/100\n",
            "59/59 [==============================] - 15s 257ms/step - loss: 0.0056 - accuracy: 0.9973 - val_loss: 21.1090 - val_accuracy: 0.5011\n",
            "Epoch 51/100\n",
            "59/59 [==============================] - 15s 257ms/step - loss: 0.0057 - accuracy: 0.9962 - val_loss: 20.9980 - val_accuracy: 0.5120\n",
            "Epoch 52/100\n",
            "59/59 [==============================] - 15s 257ms/step - loss: 0.0056 - accuracy: 0.9973 - val_loss: 20.9981 - val_accuracy: 0.5130\n",
            "Epoch 53/100\n",
            "59/59 [==============================] - 15s 260ms/step - loss: 0.0055 - accuracy: 0.9973 - val_loss: 21.0269 - val_accuracy: 0.5141\n",
            "Epoch 54/100\n",
            "59/59 [==============================] - 15s 255ms/step - loss: 0.0054 - accuracy: 0.9973 - val_loss: 21.1040 - val_accuracy: 0.4989\n",
            "Epoch 55/100\n",
            "59/59 [==============================] - 15s 260ms/step - loss: 0.0058 - accuracy: 0.9973 - val_loss: 21.0335 - val_accuracy: 0.5141\n",
            "Epoch 56/100\n",
            "59/59 [==============================] - 15s 257ms/step - loss: 0.0061 - accuracy: 0.9962 - val_loss: 20.8499 - val_accuracy: 0.5174\n",
            "Epoch 57/100\n",
            "59/59 [==============================] - 15s 259ms/step - loss: 0.0057 - accuracy: 0.9973 - val_loss: 20.8870 - val_accuracy: 0.5141\n",
            "Epoch 58/100\n",
            "59/59 [==============================] - 15s 261ms/step - loss: 0.0056 - accuracy: 0.9973 - val_loss: 20.8683 - val_accuracy: 0.5217\n",
            "Epoch 59/100\n",
            "59/59 [==============================] - 15s 253ms/step - loss: 0.0057 - accuracy: 0.9973 - val_loss: 20.8155 - val_accuracy: 0.5304\n",
            "Epoch 60/100\n",
            "59/59 [==============================] - 15s 253ms/step - loss: 0.0058 - accuracy: 0.9968 - val_loss: 20.9878 - val_accuracy: 0.4978\n",
            "Epoch 61/100\n",
            "59/59 [==============================] - 15s 256ms/step - loss: 0.0056 - accuracy: 0.9973 - val_loss: 21.0732 - val_accuracy: 0.4978\n",
            "Epoch 62/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.0056 - accuracy: 0.9973 - val_loss: 21.0879 - val_accuracy: 0.4957\n",
            "Epoch 63/100\n",
            "59/59 [==============================] - 15s 252ms/step - loss: 0.0071 - accuracy: 0.9962 - val_loss: 20.5535 - val_accuracy: 0.5065\n",
            "Epoch 64/100\n",
            "59/59 [==============================] - 15s 252ms/step - loss: 0.0085 - accuracy: 0.9952 - val_loss: 19.7615 - val_accuracy: 0.4717\n",
            "Epoch 65/100\n",
            "59/59 [==============================] - 15s 255ms/step - loss: 0.0068 - accuracy: 0.9957 - val_loss: 19.6543 - val_accuracy: 0.4717\n",
            "Epoch 66/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.0059 - accuracy: 0.9973 - val_loss: 19.2031 - val_accuracy: 0.4870\n",
            "Epoch 67/100\n",
            "59/59 [==============================] - 15s 257ms/step - loss: 0.0069 - accuracy: 0.9962 - val_loss: 19.0452 - val_accuracy: 0.5043\n",
            "Epoch 68/100\n",
            "59/59 [==============================] - 15s 255ms/step - loss: 0.0063 - accuracy: 0.9973 - val_loss: 18.7204 - val_accuracy: 0.5130\n",
            "Epoch 69/100\n",
            "59/59 [==============================] - 15s 253ms/step - loss: 0.0062 - accuracy: 0.9952 - val_loss: 18.9207 - val_accuracy: 0.4489\n",
            "Epoch 70/100\n",
            "59/59 [==============================] - 15s 253ms/step - loss: 0.0078 - accuracy: 0.9968 - val_loss: 18.9223 - val_accuracy: 0.4761\n",
            "Epoch 71/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.0077 - accuracy: 0.9962 - val_loss: 18.5479 - val_accuracy: 0.4533\n",
            "Epoch 72/100\n",
            "59/59 [==============================] - 15s 252ms/step - loss: 0.0064 - accuracy: 0.9952 - val_loss: 18.4047 - val_accuracy: 0.5109\n",
            "Epoch 73/100\n",
            "59/59 [==============================] - 15s 253ms/step - loss: 0.0066 - accuracy: 0.9968 - val_loss: 18.0444 - val_accuracy: 0.5163\n",
            "Epoch 74/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.0056 - accuracy: 0.9968 - val_loss: 18.0670 - val_accuracy: 0.4663\n",
            "Epoch 75/100\n",
            "59/59 [==============================] - 15s 252ms/step - loss: 0.0061 - accuracy: 0.9973 - val_loss: 17.9943 - val_accuracy: 0.4935\n",
            "Epoch 76/100\n",
            "59/59 [==============================] - 15s 255ms/step - loss: 0.0083 - accuracy: 0.9962 - val_loss: 18.0386 - val_accuracy: 0.5120\n",
            "Epoch 77/100\n",
            "59/59 [==============================] - 15s 255ms/step - loss: 0.0060 - accuracy: 0.9957 - val_loss: 17.6810 - val_accuracy: 0.4880\n",
            "Epoch 78/100\n",
            "59/59 [==============================] - 15s 253ms/step - loss: 0.0068 - accuracy: 0.9962 - val_loss: 17.6043 - val_accuracy: 0.5076\n",
            "Epoch 79/100\n",
            "59/59 [==============================] - 15s 252ms/step - loss: 0.0062 - accuracy: 0.9962 - val_loss: 17.7281 - val_accuracy: 0.4946\n",
            "Epoch 80/100\n",
            "59/59 [==============================] - 15s 253ms/step - loss: 0.0065 - accuracy: 0.9962 - val_loss: 18.2458 - val_accuracy: 0.4120\n",
            "Epoch 81/100\n",
            "59/59 [==============================] - 15s 253ms/step - loss: 0.0059 - accuracy: 0.9962 - val_loss: 18.0503 - val_accuracy: 0.4348\n",
            "Epoch 82/100\n",
            "59/59 [==============================] - 15s 253ms/step - loss: 0.0513 - accuracy: 0.9909 - val_loss: 21.3815 - val_accuracy: 0.3174\n",
            "Epoch 83/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 15.4650 - accuracy: 0.7898 - val_loss: 240.5007 - val_accuracy: 0.3489\n",
            "Epoch 84/100\n",
            "59/59 [==============================] - 15s 255ms/step - loss: 7.6253 - accuracy: 0.9024 - val_loss: 377.4323 - val_accuracy: 0.5076\n",
            "Epoch 85/100\n",
            "59/59 [==============================] - 15s 256ms/step - loss: 5.1942 - accuracy: 0.9448 - val_loss: 184.6972 - val_accuracy: 0.5533\n",
            "Epoch 86/100\n",
            "59/59 [==============================] - 15s 255ms/step - loss: 1.5393 - accuracy: 0.9694 - val_loss: 343.0349 - val_accuracy: 0.4946\n",
            "Epoch 87/100\n",
            "59/59 [==============================] - 15s 255ms/step - loss: 0.5602 - accuracy: 0.9855 - val_loss: 118.9948 - val_accuracy: 0.5587\n",
            "Epoch 88/100\n",
            "59/59 [==============================] - 15s 255ms/step - loss: 0.6938 - accuracy: 0.9834 - val_loss: 250.6674 - val_accuracy: 0.5272\n",
            "Epoch 89/100\n",
            "59/59 [==============================] - 15s 252ms/step - loss: 0.2452 - accuracy: 0.9920 - val_loss: 292.2137 - val_accuracy: 0.5304\n",
            "Epoch 90/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.1154 - accuracy: 0.9946 - val_loss: 290.1276 - val_accuracy: 0.5326\n",
            "Epoch 91/100\n",
            "59/59 [==============================] - 15s 252ms/step - loss: 0.0992 - accuracy: 0.9941 - val_loss: 289.8494 - val_accuracy: 0.5304\n",
            "Epoch 92/100\n",
            "59/59 [==============================] - 15s 255ms/step - loss: 0.1575 - accuracy: 0.9962 - val_loss: 289.6742 - val_accuracy: 0.5163\n",
            "Epoch 93/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.0402 - accuracy: 0.9968 - val_loss: 289.7121 - val_accuracy: 0.5228\n",
            "Epoch 94/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.0819 - accuracy: 0.9957 - val_loss: 289.7369 - val_accuracy: 0.5261\n",
            "Epoch 95/100\n",
            "59/59 [==============================] - 15s 253ms/step - loss: 0.0464 - accuracy: 0.9957 - val_loss: 289.9908 - val_accuracy: 0.5272\n",
            "Epoch 96/100\n",
            "59/59 [==============================] - 15s 253ms/step - loss: 0.0338 - accuracy: 0.9973 - val_loss: 289.5905 - val_accuracy: 0.5239\n",
            "Epoch 97/100\n",
            "59/59 [==============================] - 15s 253ms/step - loss: 0.0856 - accuracy: 0.9946 - val_loss: 289.6847 - val_accuracy: 0.5304\n",
            "Epoch 98/100\n",
            "59/59 [==============================] - 15s 253ms/step - loss: 0.0485 - accuracy: 0.9962 - val_loss: 289.2402 - val_accuracy: 0.5185\n",
            "Epoch 99/100\n",
            "59/59 [==============================] - 15s 252ms/step - loss: 0.0213 - accuracy: 0.9962 - val_loss: 289.1917 - val_accuracy: 0.5228\n",
            "Epoch 100/100\n",
            "59/59 [==============================] - 15s 254ms/step - loss: 0.0758 - accuracy: 0.9952 - val_loss: 289.6491 - val_accuracy: 0.5272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(x_test_scaled)\n",
        "y_pred = [np.argmax(element) for element in y_pred]\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_pred, y_test))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "RNl5NGyfh-9D",
        "outputId": "c3121015-f423-4ff1-faa6-ed88936fe807",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6872309899569584\n",
            "[[ 21   0   4   4   0   0  20   2   0   0]\n",
            " [  1 108   1   0   0   0   1   0   0   0]\n",
            " [  0   0  54   4   6   1  16   0   0   0]\n",
            " [  1   0   1  73   9   2   4   6   2   3]\n",
            " [  2   6   1  23  89   2  10   4   1   3]\n",
            " [  0   0   1   6   0  24   1   2   2   0]\n",
            " [  1   0   5   0   3   0  36   1   0   2]\n",
            " [  1   2   0  13   5   0   0  14   0   5]\n",
            " [  0   0   0   0   0   0   0   0  25   1]\n",
            " [  0   0   5   7   2   5   8   0   0  35]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(f\"{classification_report(y_test, y_pred)}\" )"
      ],
      "metadata": {
        "id": "TBUiA74Mi6XX",
        "outputId": "f9a23b4b-aebe-4a72-e902-0177ec112fa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.41      0.54        51\n",
            "           1       0.93      0.97      0.95       111\n",
            "           2       0.75      0.67      0.71        81\n",
            "           3       0.56      0.72      0.63       101\n",
            "           4       0.78      0.63      0.70       141\n",
            "           5       0.71      0.67      0.69        36\n",
            "           6       0.38      0.75      0.50        48\n",
            "           7       0.48      0.35      0.41        40\n",
            "           8       0.83      0.96      0.89        26\n",
            "           9       0.71      0.56      0.63        62\n",
            "\n",
            "    accuracy                           0.69       697\n",
            "   macro avg       0.69      0.67      0.66       697\n",
            "weighted avg       0.72      0.69      0.69       697\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RandomForest Classifier"
      ],
      "metadata": {
        "id": "CWiOT3yBEDyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model=RandomForestClassifier(n_estimators=100)"
      ],
      "metadata": {
        "id": "NLpI7Zqzk3La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train)\n",
        "y_pred=model.predict(X_test)"
      ],
      "metadata": {
        "id": "Kz9wOXOCk3Nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ztJ61Dcl9bR",
        "outputId": "0dbed983-b9bc-4820-e322-9f2fddbf4ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7712918660287081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6fJWrn-k3P3",
        "outputId": "40da8193-f927-4f31-924d-9ccc55fd6944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 40,   2,   3,   4,   4,   0,  20,   0,   0,   0],\n",
              "       [  0, 178,   0,   1,   2,   0,   0,   0,   0,   0],\n",
              "       [  2,   4,  96,   6,   3,   0,  10,   0,   0,   0],\n",
              "       [  1,   3,   2, 115,  31,   1,   2,   1,   0,   0],\n",
              "       [  0,   6,   0,  13, 185,   0,   1,   2,   0,   0],\n",
              "       [  2,   0,   1,   3,   2,  39,   2,   2,   0,   0],\n",
              "       [  1,   1,   2,   0,   0,   0,  57,   0,   0,   0],\n",
              "       [  4,   3,   2,  26,   8,   0,   1,  13,   1,   7],\n",
              "       [  0,   0,   2,   3,   0,   0,   0,   0,  37,   0],\n",
              "       [  4,   0,  12,   8,   4,   1,   3,  10,   0,  46]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lh5W7ObmFIX",
        "outputId": "b2e98b40-6eda-4586-e521-d3aa7ee8ea99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.55      0.63        73\n",
            "           1       0.90      0.98      0.94       181\n",
            "           2       0.80      0.79      0.80       121\n",
            "           3       0.64      0.74      0.69       156\n",
            "           4       0.77      0.89      0.83       207\n",
            "           5       0.95      0.76      0.85        51\n",
            "           6       0.59      0.93      0.73        61\n",
            "           7       0.46      0.20      0.28        65\n",
            "           8       0.97      0.88      0.93        42\n",
            "           9       0.87      0.52      0.65        88\n",
            "\n",
            "    accuracy                           0.77      1045\n",
            "   macro avg       0.77      0.73      0.73      1045\n",
            "weighted avg       0.77      0.77      0.76      1045\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0CdmM7wEk3Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN classifier"
      ],
      "metadata": {
        "id": "mNOj5kCTnevT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=7)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmQlQ2AnoKe4",
        "outputId": "cefb84bd-9bde-4ca3-bc0f-becc979a1d60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.06889952153110047\n",
            "[[  6   0   0   0   0   0  67   0   0   0]\n",
            " [ 11   0   0   0   0   0 170   0   0   0]\n",
            " [  6   0   2   0   0   0 113   0   0   0]\n",
            " [  7   0   0   2   0   0 147   0   0   0]\n",
            " [  9   0   0   0   2   0 196   0   0   0]\n",
            " [  1   0   0   0   0   0  50   0   0   0]\n",
            " [  1   0   0   0   0   0  60   0   0   0]\n",
            " [  1   0   0   0   0   0  64   0   0   0]\n",
            " [  3   0   0   0   0   0  39   0   0   0]\n",
            " [  6   0   0   0   0   0  82   0   0   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.12      0.08      0.10        73\n",
            "           1       0.00      0.00      0.00       181\n",
            "           2       1.00      0.02      0.03       121\n",
            "           3       1.00      0.01      0.03       156\n",
            "           4       1.00      0.01      0.02       207\n",
            "           5       0.00      0.00      0.00        51\n",
            "           6       0.06      0.98      0.11        61\n",
            "           7       0.00      0.00      0.00        65\n",
            "           8       0.00      0.00      0.00        42\n",
            "           9       0.00      0.00      0.00        88\n",
            "\n",
            "    accuracy                           0.07      1045\n",
            "   macro avg       0.32      0.11      0.03      1045\n",
            "weighted avg       0.47      0.07      0.02      1045\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,15):\n",
        "    knn = KNeighborsClassifier(n_neighbors=i)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmCt7NYpo-Gv",
        "outputId": "250ad277-913a-44bc-9da4-0aff2a6a3b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.11961722488038277\n",
            "Accuracy: 0.0861244019138756\n",
            "Accuracy: 0.08325358851674641\n",
            "Accuracy: 0.0861244019138756\n",
            "Accuracy: 0.08038277511961722\n",
            "Accuracy: 0.07655502392344497\n",
            "Accuracy: 0.06889952153110047\n",
            "Accuracy: 0.06889952153110047\n",
            "Accuracy: 0.06411483253588517\n",
            "Accuracy: 0.06220095693779904\n",
            "Accuracy: 0.06315789473684211\n",
            "Accuracy: 0.06315789473684211\n",
            "Accuracy: 0.06220095693779904\n",
            "Accuracy: 0.06124401913875598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ys7vm3e4o-Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM classifier "
      ],
      "metadata": {
        "id": "LjxenVEvDgVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ZlDvVy3aDlBA",
        "outputId": "4e6fbf67-7219-4842-eb05-381d7f5766cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "TOAJrHmRDlDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "ups2Rpc0DlGz",
        "outputId": "c7064987-fe28-483f-80fe-93ae7101598f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8172248803827751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "UToOi2jEEaUt",
        "outputId": "71965138-c444-4adb-a803-cc2f72ac1d6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 44   0   4   2   3   0  19   1   0   0]\n",
            " [  0 175   1   2   2   1   0   0   0   0]\n",
            " [  0   0 108   2   3   2   3   1   0   2]\n",
            " [  0   1   2 124  15   1   1   9   0   3]\n",
            " [  0   1   2  13 182   2   0   4   0   3]\n",
            " [  0   0   0   2   1  42   2   4   0   0]\n",
            " [  0   1   4   2   4   0  50   0   0   0]\n",
            " [  0   0   3  17   5   1   0  33   1   5]\n",
            " [  0   0   0   2   0   0   1   0  38   1]\n",
            " [  0   0   8   7   2   0   3  10   0  58]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.60      0.75        73\n",
            "           1       0.98      0.97      0.97       181\n",
            "           2       0.82      0.89      0.85       121\n",
            "           3       0.72      0.79      0.75       156\n",
            "           4       0.84      0.88      0.86       207\n",
            "           5       0.86      0.82      0.84        51\n",
            "           6       0.63      0.82      0.71        61\n",
            "           7       0.53      0.51      0.52        65\n",
            "           8       0.97      0.90      0.94        42\n",
            "           9       0.81      0.66      0.73        88\n",
            "\n",
            "    accuracy                           0.82      1045\n",
            "   macro avg       0.82      0.79      0.79      1045\n",
            "weighted avg       0.83      0.82      0.82      1045\n",
            "\n"
          ]
        }
      ]
    }
  ]
}